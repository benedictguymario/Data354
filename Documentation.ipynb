{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ğŸ“š Documentation de la solution : Chatbot Ecofin ğŸ¤–**\n",
    "\n",
    "## **ğŸ” Introduction**\n",
    "\n",
    "Ce code implÃ©mente un chatbot intelligent utilisant **Chainlit** et l'API **Google Generative AI (GenAI)**, combinÃ© Ã  un moteur d'**embedding** basÃ© sur **Sentence-Transformers** pour la recherche de contenu pertinent dans une base de donnÃ©es **Chroma**. Le chatbot aide les utilisateurs Ã  obtenir des informations dÃ©taillÃ©es sur des articles du site *Ecofin*.\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ›  Composants principaux**\n",
    "\n",
    "1. **Chainlit** ğŸ’¬ : UtilisÃ© pour la gestion de la conversation, y compris l'authentification, l'historique et l'interaction avec l'utilisateur.\n",
    "2. **Sentence-Transformers** ğŸ§  : UtilisÃ© pour transformer les textes en embeddings et permettre des recherches dans la base de donnÃ©es.\n",
    "3. **Google Generative AI (GenAI)** ğŸ¤– : UtilisÃ© pour gÃ©nÃ©rer des rÃ©ponses aux questions des utilisateurs en fonction du prompt.\n",
    "4. **Chroma** ğŸ’¾ : Une base de donnÃ©es vectorielle permettant de stocker et rechercher des documents en fonction de leur similaritÃ©.\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸš€ PrÃ©-requis**\n",
    "\n",
    "Avant de lancer l'application, assurez-vous que vous avez installÃ© toutes les dÃ©pendances nÃ©cessaires et configurÃ© l'environnement.\n",
    "\n",
    "### **DÃ©pendances Python** ğŸ“¦\n",
    "\n",
    "- `chainlit` : Pour crÃ©er et gÃ©rer l'interface de conversation.\n",
    "- `langchain` : Pour gÃ©rer la base de donnÃ©es vectorielle Chroma.\n",
    "- `sentence-transformers` : Pour transformer le texte en embeddings.\n",
    "- `google-generativeai` : API de gÃ©nÃ©ration de texte de Google.\n",
    "- `python-dotenv` : Pour charger les variables d'environnement Ã  partir d'un fichier `.env`.\n",
    "\n",
    "Installez ces bibliothÃ¨ques avec la commande `pip` :\n",
    "\n",
    "```bash\n",
    "pip install chainlit langchain sentence-transformers google-generativeai python-dotenv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ”‘ ClÃ© API GenAI**\n",
    "\n",
    "1. CrÃ©ez un fichier `.env` dans le rÃ©pertoire racine de votre projet et ajoutez votre clÃ© API comme suit :\n",
    "\n",
    "```plaintext\n",
    "GENAI_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ§‘â€ğŸ’» Structure du code**\n",
    "\n",
    "### 1. **Initialisation et chargement des bibliothÃ¨ques** ğŸ”Œ\n",
    "\n",
    "Le code commence par importer les bibliothÃ¨ques nÃ©cessaires et charger les variables d'environnement.\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GENAI_API_KEY\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "```\n",
    "\n",
    "### 2. **Classe `SentenceTransformerEmbeddings` ğŸ§ **\n",
    "\n",
    "Cette classe encode les documents et les questions en embeddings grÃ¢ce Ã  **Sentence-Transformers**.\n",
    "\n",
    "```python\n",
    "class SentenceTransformerEmbeddings:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, convert_to_tensor=True).tolist()\n",
    "\n",
    "    def embed_question(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, convert_to_tensor=True).tolist()\n",
    "```\n",
    "\n",
    "### 3. **Chargement de la base de donnÃ©es Chroma ğŸ“š**\n",
    "\n",
    "La fonction `Obtenir_db` charge la base de donnÃ©es Chroma persistÃ©e contenant les documents.\n",
    "\n",
    "```python\n",
    "def Obtenir_db(chroma_db_path: str, fonc_embed: SentenceTransformerEmbeddings):\n",
    "    try:\n",
    "        db = Chroma(persist_directory=chroma_db_path, embedding_function=fonc_embed)\n",
    "    except Exception as e:\n",
    "        return None, f\"Erreur : Impossible d'accÃ©der Ã  la collection. DÃ©tail : {str(e)}\"\n",
    "    return db, None\n",
    "```\n",
    "\n",
    "### 4. **Recherche de contexte dans la base de donnÃ©es ğŸ”**\n",
    "\n",
    "La fonction `Obtenir_contexte` effectue une recherche dans la base pour rÃ©cupÃ©rer des documents pertinents en fonction de la question de l'utilisateur.\n",
    "\n",
    "```python\n",
    "def Obtenir_contexte(db, question: str, fonc_embed: SentenceTransformerEmbeddings, k: int = 3) -> str:\n",
    "    question_embedding = fonc_embed.embed_question(question)\n",
    "    results = db.similarity_search_by_vector(question_embedding, k=k)\n",
    "    if not results:\n",
    "        return \"Aucun contexte trouvÃ©.\"\n",
    "    docs = [result.page_content for result in results]\n",
    "    contexte = \"\\n\\n\".join(docs)\n",
    "    return contexte\n",
    "```\n",
    "\n",
    "### 5. **CrÃ©ation du prompt âœï¸**\n",
    "\n",
    "Le prompt gÃ©nÃ©rÃ© inclut l'historique de la conversation et le contexte pertinent. Il est envoyÃ© Ã  l'API GenAI pour gÃ©nÃ©rer une rÃ©ponse.\n",
    "\n",
    "```python\n",
    "def Creat_prompt(question: str, reponse: str, historique: List[Dict[str, str]]) -> str:\n",
    "    historique_str = \"\\n\".join([f\"Utilisateur : {h['question']}\\nAssistant : {h['response']}\" for h in historique])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Vous Ãªtes un assistant expert chargÃ© de rÃ©pondre aux questions des utilisateurs de maniÃ¨re claire, dÃ©taillÃ©e et prÃ©cise. Voici les instructions Ã  suivre :\n",
    "    0. **salutation**:...\n",
    "    1. **Langue** :...\n",
    "    ...\n",
    "    **Contexte** : {reponse}\n",
    "    **Question** : {question}\n",
    "    ---\n",
    "    **RÃ©ponse utile** :\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "### 6. **GÃ©nÃ©ration de la rÃ©ponse ğŸ’¡**\n",
    "\n",
    "La fonction `Reponse` interroge l'API GenAI avec le prompt gÃ©nÃ©rÃ© et renvoie la rÃ©ponse.\n",
    "\n",
    "```python\n",
    "def Reponse(chatbot, prompt: str) -> str:\n",
    "    try:\n",
    "        response = chatbot.generate_content(prompt)\n",
    "        final_response = response.text\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors de la gÃ©nÃ©ration de la rÃ©ponse : {str(e)}\"\n",
    "    return final_response\n",
    "```\n",
    "\n",
    "### 7. **Gestionnaire d'Ã©vÃ©nements Chainlit ğŸ®**\n",
    "\n",
    "Les gestionnaires d'Ã©vÃ©nements Chainlit dÃ©finissent le comportement du chatbot, notamment lors du dÃ©marrage de la conversation et Ã  la rÃ©ception des messages. L'historique est mis Ã  jour et une enquÃªte de satisfaction est envoyÃ©e Ã  l'utilisateur aprÃ¨s chaque rÃ©ponse.\n",
    "\n",
    "```python\n",
    "@cl.on_chat_start\n",
    "async def chat_start():\n",
    "    fonc_embed = SentenceTransformerEmbeddings()\n",
    "    db, error = Obtenir_db(\"Chromadb\", fonc_embed)\n",
    "    if error:\n",
    "        await cl.Message(content=f\"Erreur lors du chargement de la base de donnÃ©es : {error}\").send()\n",
    "        return\n",
    "    ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸš€ Lancer l'application**\n",
    "\n",
    "1. **DÃ©marrer l'application** : Vous pouvez dÃ©marrer le chatbot avec la commande suivante :\n",
    "\n",
    "```bash\n",
    "chainlit run  test.py\n",
    "```\n",
    "\n",
    "2. **Interaction avec l'utilisateur** : Le chatbot commencera Ã  poser des questions pour obtenir des informations sur les articles. L'utilisateur pourra poser des questions et le chatbot rÃ©pondra en fonction du contenu de la base de donnÃ©es.\n",
    "\n",
    "3. **RÃ©ponses et enquÃªte de satisfaction** : AprÃ¨s chaque rÃ©ponse, une enquÃªte de satisfaction est envoyÃ©e pour savoir si l'utilisateur est satisfait de la rÃ©ponse.\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ¨ Personnalisation**\n",
    "\n",
    "- **Choix du modÃ¨le** : Dans la fonction `chat_profile`, vous pouvez dÃ©finir diffÃ©rents modÃ¨les pour le chatbot, permettant Ã  l'utilisateur de choisir entre plusieurs options.\n",
    "- **Base de donnÃ©es Chroma** : Vous pouvez ajuster le chemin du fichier Chroma et le nombre de documents retournÃ©s (via le paramÃ¨tre `k`).\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ”š Conclusion**\n",
    "\n",
    "Ce chatbot utilise une combinaison d'outils puissants pour fournir des rÃ©ponses intelligentes et pertinentes basÃ©es sur des articles du site *Ecofin*. Il gÃ¨re l'historique des conversations, le contexte pertinent des articles, et fournit des rÃ©ponses personnalisÃ©es tout en recueillant des retours utilisateurs pour amÃ©liorer son service.ğŸ˜Š\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data354",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
