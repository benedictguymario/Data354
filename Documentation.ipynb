{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **📚 Documentation de la solution : Chatbot Ecofin 🤖**\n",
    "\n",
    "## **🔍 Introduction**\n",
    "\n",
    "Ce code implémente un chatbot intelligent utilisant **Chainlit** et l'API **Google Generative AI (GenAI)**, combiné à un moteur d'**embedding** basé sur **Sentence-Transformers** pour la recherche de contenu pertinent dans une base de données **Chroma**. Le chatbot aide les utilisateurs à obtenir des informations détaillées sur des articles du site *Ecofin*.\n",
    "\n",
    "---\n",
    "\n",
    "## **🛠 Composants principaux**\n",
    "\n",
    "1. **Chainlit** 💬 : Utilisé pour la gestion de la conversation, y compris l'authentification, l'historique et l'interaction avec l'utilisateur.\n",
    "2. **Sentence-Transformers** 🧠 : Utilisé pour transformer les textes en embeddings et permettre des recherches dans la base de données.\n",
    "3. **Google Generative AI (GenAI)** 🤖 : Utilisé pour générer des réponses aux questions des utilisateurs en fonction du prompt.\n",
    "4. **Chroma** 💾 : Une base de données vectorielle permettant de stocker et rechercher des documents en fonction de leur similarité.\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Pré-requis**\n",
    "\n",
    "Avant de lancer l'application, assurez-vous que vous avez installé toutes les dépendances nécessaires et configuré l'environnement.\n",
    "\n",
    "### **Dépendances Python** 📦\n",
    "\n",
    "- `chainlit` : Pour créer et gérer l'interface de conversation.\n",
    "- `langchain` : Pour gérer la base de données vectorielle Chroma.\n",
    "- `sentence-transformers` : Pour transformer le texte en embeddings.\n",
    "- `google-generativeai` : API de génération de texte de Google.\n",
    "- `python-dotenv` : Pour charger les variables d'environnement à partir d'un fichier `.env`.\n",
    "\n",
    "Installez ces bibliothèques avec la commande `pip` :\n",
    "\n",
    "```bash\n",
    "pip install chainlit langchain sentence-transformers google-generativeai python-dotenv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **🔑 Clé API GenAI**\n",
    "\n",
    "1. Créez un fichier `.env` dans le répertoire racine de votre projet et ajoutez votre clé API comme suit :\n",
    "\n",
    "```plaintext\n",
    "GENAI_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **🧑‍💻 Structure du code**\n",
    "\n",
    "### 1. **Initialisation et chargement des bibliothèques** 🔌\n",
    "\n",
    "Le code commence par importer les bibliothèques nécessaires et charger les variables d'environnement.\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GENAI_API_KEY\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "```\n",
    "\n",
    "### 2. **Classe `SentenceTransformerEmbeddings` 🧠**\n",
    "\n",
    "Cette classe encode les documents et les questions en embeddings grâce à **Sentence-Transformers**.\n",
    "\n",
    "```python\n",
    "class SentenceTransformerEmbeddings:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, convert_to_tensor=True).tolist()\n",
    "\n",
    "    def embed_question(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, convert_to_tensor=True).tolist()\n",
    "```\n",
    "\n",
    "### 3. **Chargement de la base de données Chroma 📚**\n",
    "\n",
    "La fonction `Obtenir_db` charge la base de données Chroma persistée contenant les documents.\n",
    "\n",
    "```python\n",
    "def Obtenir_db(chroma_db_path: str, fonc_embed: SentenceTransformerEmbeddings):\n",
    "    try:\n",
    "        db = Chroma(persist_directory=chroma_db_path, embedding_function=fonc_embed)\n",
    "    except Exception as e:\n",
    "        return None, f\"Erreur : Impossible d'accéder à la collection. Détail : {str(e)}\"\n",
    "    return db, None\n",
    "```\n",
    "\n",
    "### 4. **Recherche de contexte dans la base de données 🔍**\n",
    "\n",
    "La fonction `Obtenir_contexte` effectue une recherche dans la base pour récupérer des documents pertinents en fonction de la question de l'utilisateur.\n",
    "\n",
    "```python\n",
    "def Obtenir_contexte(db, question: str, fonc_embed: SentenceTransformerEmbeddings, k: int = 3) -> str:\n",
    "    question_embedding = fonc_embed.embed_question(question)\n",
    "    results = db.similarity_search_by_vector(question_embedding, k=k)\n",
    "    if not results:\n",
    "        return \"Aucun contexte trouvé.\"\n",
    "    docs = [result.page_content for result in results]\n",
    "    contexte = \"\\n\\n\".join(docs)\n",
    "    return contexte\n",
    "```\n",
    "\n",
    "### 5. **Création du prompt ✍️**\n",
    "\n",
    "Le prompt généré inclut l'historique de la conversation et le contexte pertinent. Il est envoyé à l'API GenAI pour générer une réponse.\n",
    "\n",
    "```python\n",
    "def Creat_prompt(question: str, reponse: str, historique: List[Dict[str, str]]) -> str:\n",
    "    historique_str = \"\\n\".join([f\"Utilisateur : {h['question']}\\nAssistant : {h['response']}\" for h in historique])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Vous êtes un assistant expert chargé de répondre aux questions des utilisateurs de manière claire, détaillée et précise. Voici les instructions à suivre :\n",
    "    0. **salutation**:...\n",
    "    1. **Langue** :...\n",
    "    ...\n",
    "    **Contexte** : {reponse}\n",
    "    **Question** : {question}\n",
    "    ---\n",
    "    **Réponse utile** :\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "### 6. **Génération de la réponse 💡**\n",
    "\n",
    "La fonction `Reponse` interroge l'API GenAI avec le prompt généré et renvoie la réponse.\n",
    "\n",
    "```python\n",
    "def Reponse(chatbot, prompt: str) -> str:\n",
    "    try:\n",
    "        response = chatbot.generate_content(prompt)\n",
    "        final_response = response.text\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors de la génération de la réponse : {str(e)}\"\n",
    "    return final_response\n",
    "```\n",
    "\n",
    "### 7. **Gestionnaire d'événements Chainlit 🎮**\n",
    "\n",
    "Les gestionnaires d'événements Chainlit définissent le comportement du chatbot, notamment lors du démarrage de la conversation et à la réception des messages. L'historique est mis à jour et une enquête de satisfaction est envoyée à l'utilisateur après chaque réponse.\n",
    "\n",
    "```python\n",
    "@cl.on_chat_start\n",
    "async def chat_start():\n",
    "    fonc_embed = SentenceTransformerEmbeddings()\n",
    "    db, error = Obtenir_db(\"Chromadb\", fonc_embed)\n",
    "    if error:\n",
    "        await cl.Message(content=f\"Erreur lors du chargement de la base de données : {error}\").send()\n",
    "        return\n",
    "    ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Lancer l'application**\n",
    "\n",
    "1. **Démarrer l'application** : Vous pouvez démarrer le chatbot avec la commande suivante :\n",
    "\n",
    "```bash\n",
    "chainlit run  test.py\n",
    "```\n",
    "\n",
    "2. **Interaction avec l'utilisateur** : Le chatbot commencera à poser des questions pour obtenir des informations sur les articles. L'utilisateur pourra poser des questions et le chatbot répondra en fonction du contenu de la base de données.\n",
    "\n",
    "3. **Réponses et enquête de satisfaction** : Après chaque réponse, une enquête de satisfaction est envoyée pour savoir si l'utilisateur est satisfait de la réponse.\n",
    "\n",
    "---\n",
    "\n",
    "## **🎨 Personnalisation**\n",
    "\n",
    "- **Choix du modèle** : Dans la fonction `chat_profile`, vous pouvez définir différents modèles pour le chatbot, permettant à l'utilisateur de choisir entre plusieurs options.\n",
    "- **Base de données Chroma** : Vous pouvez ajuster le chemin du fichier Chroma et le nombre de documents retournés (via le paramètre `k`).\n",
    "\n",
    "---\n",
    "\n",
    "## **🔚 Conclusion**\n",
    "\n",
    "Ce chatbot utilise une combinaison d'outils puissants pour fournir des réponses intelligentes et pertinentes basées sur des articles du site *Ecofin*. Il gère l'historique des conversations, le contexte pertinent des articles, et fournit des réponses personnalisées tout en recueillant des retours utilisateurs pour améliorer son service.😊\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data354",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
